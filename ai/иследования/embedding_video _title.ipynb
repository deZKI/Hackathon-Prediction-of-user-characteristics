{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "pip install pandas scikit-learn numpy transformers torch tqdm sentence-transformers\n",
   "id": "8cdb57a761fbc250"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea65ba75-9d01-4e34-9668-64499aff369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jet\\anaconda3\\envs\\cud1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89bfa1-29d7-4b34-ad82-13ba5055ceab",
   "metadata": {},
   "source": [
    "**Цель**: предсказание пола и возрастной категории пользователей на основе их истории просмотров видео. Используются:\n",
    "- Заголовки видео\n",
    "- Демографические данные\n",
    "- Технические характеристики устройств\n",
    "\n",
    "## Используемые библиотеки\n",
    "- `sentence-transformers` — для генерации эмбеддингов заголовков.\n",
    "- `CatBoostClassifier` — для обучения модели с категориальными признаками.\n",
    "\n",
    "## Этапы работы\n",
    "1. **Загрузка и объединение данных**  \n",
    "   Объединение таблиц с данными о просмотрах, видео и целевых переменных.\n",
    "   \n",
    "2. **Очистка заголовков**  \n",
    "   Функция `clean_title` обрабатывает заголовки видео, удаляя лишние символы и ненужные слова для повышения качества предсказаний.\n",
    "\n",
    "3. **Генерация эмбеддингов заголовков**  \n",
    "   Модель `SentenceTransformer` преобразует заголовки видео в числовые эмбеддинги, которые используются для обучения модели.\n",
    "\n",
    "4. **Агрегация данных по пользователям**  \n",
    "   Для каждого пользователя агрегируются средние эмбеддинги заголовков, а также другие характеристики (время просмотра, технические данные).\n",
    "\n",
    "5. **Обучение модели**  \n",
    "   Модель `CatBoostClassifier` обучается на данных с категориальными признаками для предсказания пола и возрастной категории.\n",
    "\n",
    "6. **Оценка модели**  \n",
    "   Метрики точности и F1 выводятся для оценки качества работы модели.\n",
    "\n",
    "# Результаты предсказания\n",
    "\n",
    "## Предсказание возрастной категории\n",
    "**F1 Score (weighted)**: `0.4541`\n",
    "\n",
    "## Предсказание пола\n",
    "**F1 Score (weighted)**: `0.7480`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b7b62b-4eed-41d1-bbb5-130270917e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка заголовков\n",
    "key_phrases = list(set([\"Женский стендап\", \"Comedy\", \"Мстители\", \"Мужское Женское\", \"На ножах\", \"Однажды в России\",\n",
    "                        \"Очень странные дела\", \"Пацаны\", \"Свадьба\", \"Свидание\", \"Сумерки\", \"Теория Большого взрыва\",\n",
    "                        \"Экстрасенсы\", \"Во все тяжкие\", \"Мужское / Женское\", \"ТРУШНЫЙ\", \"Эмили в Париже\", \"Шерлок\",\n",
    "                        \"Четыре жены\", \"Черный список\", \"Человек-паук\", \"Человек-невидимка\", \"Хороший доктор\",\n",
    "                        \"Властелин\", \"Веном\", \"Ван-Пис\", \"Бумажный\", \"Бриджертоны\", \"БЕРЕМЕННА\", \"Аркейн\", \"Аквамен\",\n",
    "                        \"Аватар\", \"Секрет на миллион\", \"Пожалуйста не рассказывай!\", \"Морские дьяволы\", \"За гранью\",\n",
    "                        \"ДНК\", \"Следствие вели\", \"Comedy Club\", \"Stand Up\", \"Ходячие мертвецы\", \"ТНТ\", \"Трансформеры\",\n",
    "                        \"Сёгун\", \"МАМА\", \"Сумеречные охотники\", \"Одни из нас\", \"Пацанки\", \"Острые козырьки\",\n",
    "                        \"Маша и Медведь\", \"Молодые ножи\", \"Звёздные войны\", \"Пучков\", \"Gravity Falls\", \"Гравити Фолз\",\n",
    "                        \"Гарри Поттер\",\"Аниме\",\"Fallout\"]))\n",
    "\n",
    "# Приводим все ключевые фразы к нижнему регистру для удобства сравнения\n",
    "key_phrases_lower = [phrase.lower() for phrase in key_phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29b89c9a-de88-4fbe-96a6-fbaa7db66e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = pd.read_csv('all_events.csv')\n",
    "train_events = pd.read_csv('train_events.csv')\n",
    "video_info = pd.read_csv('video_info_v2.csv')\n",
    "train_targets = pd.read_csv('train_targets.csv')\n",
    "\n",
    "# Объединение данных\n",
    "train_data = pd.merge(train_events, train_targets, on='viewer_uid', how='left')\n",
    "train_data = pd.merge(train_data, video_info, on='rutube_video_id', how='left')\n",
    "all_events = pd.merge(all_events, video_info, on='rutube_video_id', how='left')\n",
    "\n",
    "# Разделение на обучающие и тестовые данные\n",
    "unique_viewers = train_data['viewer_uid'].unique()\n",
    "train_viewers, test_viewers = train_test_split(unique_viewers, test_size=0.2, random_state=42)\n",
    "train_df = train_data[train_data['viewer_uid'].isin(train_viewers)].reset_index(drop=True)\n",
    "test_df = train_data[train_data['viewer_uid'].isin(test_viewers)].reset_index(drop=True)\n",
    "\n",
    "# Проверка на пересечения пользователей\n",
    "intersection = set(train_viewers).intersection(set(test_viewers))\n",
    "if len(intersection) == 0:\n",
    "    print(\"Пересечений пользователей между train и test нет\")\n",
    "else:\n",
    "    print(f\"Предупреждение: {len(intersection)} пересекающихся пользователей между train и test\")\n",
    "\n",
    "# Категориальные признаки\n",
    "categorical_features = ['region', 'ua_device_type', 'ua_client_type', 'ua_os',\n",
    "                        'ua_client_name', 'rutube_video_id', 'author_id', 'category']\n",
    "\n",
    "categorical_mapping = {}\n",
    "for col in categorical_features:\n",
    "    unique_values = train_df[col].astype(str).unique().tolist()\n",
    "    mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    categorical_mapping[col] = mapping\n",
    "    train_df[col] = train_df[col].astype(str).map(mapping)\n",
    "    test_df[col] = test_df[col].astype(str).map(mapping).fillna(len(mapping)).astype(int)\n",
    "\n",
    " \n",
    "\n",
    "def clean_title(title):\n",
    "    # Приводим заголовок к нижнему регистру для корректного сравнения\n",
    "    title_lower = title.lower()\n",
    "\n",
    "    # Список для хранения всех найденных фраз\n",
    "    found_phrases = []\n",
    "\n",
    "    # Проверяем, если заголовок содержит одну из ключевых фраз\n",
    "    for phrase, phrase_lower in zip(key_phrases, key_phrases_lower):\n",
    "        if phrase_lower in title_lower:\n",
    "            found_phrases.append(phrase)  # Добавляем оригинальную ключевую фразу в список\n",
    "\n",
    "    # Если найдены ключевые фразы, возвращаем их через запятую\n",
    "    if found_phrases:\n",
    "        return ', '.join(found_phrases)\n",
    "\n",
    "    # Обработка для ASMR\n",
    "    if 'асмр' in title_lower or 'asmr' in title_lower:\n",
    "        return 'АСМР'\n",
    "    \n",
    "    # Общая очистка для других заголовков\n",
    "    title = re.sub(r'(сезон|выпуск|серия|финал|день|часть|ФИНАЛ|Серия|Новогодний)', '', title, flags=re.IGNORECASE)\n",
    "    title = title.replace('Новая Битва экстрасенсов', 'Экстрасенсы').replace('экстрасенсов', 'Экстрасенсы')\n",
    "    title = title.replace('Битва', '').replace('сильнейших', '').replace('шефов .', 'шеф')\n",
    "    title = title.replace('Битва', '').replace('сильнейших', '')  # Удаление \"Битва сильнейших\"\n",
    "    title = title.replace('шефов .', 'шеф')\n",
    "    # Удаление лишних пробелов и символов\n",
    "    title = re.sub(r'\\d+', '', title)  # Удаление цифр\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)  # Удаление спецсимволов\n",
    "    title = re.sub(r'\\s+', ' ', title)  # Удаление лишних пробелов\n",
    "\n",
    "    # Возвращаем очищенный заголовок\n",
    "    return title.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Генерация эмбеддингов\n",
    "def generate_embeddings(clean_df, batch_size=8):\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(clean_df), batch_size), desc=\"Processing batches\"):\n",
    "        batch = clean_df['cleaned_title'][i:i + batch_size].tolist()\n",
    "        batch_embeddings = model.encode(batch, device=device)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    clean_df['title_embedding1'] = list(embeddings)\n",
    "    return clean_df\n",
    "\n",
    "# Агрегация данных по пользователям\n",
    "def aggregate_user_data(clean_df):\n",
    "    user_embeddings = clean_df.groupby('viewer_uid')['title_embedding1'].apply(lambda x: np.mean(x.tolist(), axis=0))\n",
    "    user_info = clean_df.groupby('viewer_uid').agg({\n",
    "        'age': 'max' if 'age' in clean_df.columns else None,\n",
    "        'sex': 'first' if 'sex' in clean_df.columns else None,\n",
    "        'region': lambda x: x.mode()[0],\n",
    "        'ua_device_type': lambda x: x.mode()[0],\n",
    "        'ua_client_type': lambda x: x.mode()[0],\n",
    "        'ua_os': lambda x: x.mode()[0],\n",
    "        'ua_client_name': lambda x: x.mode()[0],\n",
    "        'total_watchtime': 'sum',\n",
    "        'category': lambda x: x.mode()[0],\n",
    "        'duration': 'sum',\n",
    "        'age_class': (lambda x: x.mode()[0]) if 'age_class' in clean_df.columns else None,\n",
    "    }).reset_index()\n",
    "    user_info['mean_title_embedding'] = user_embeddings.values\n",
    "    return user_info\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(X_train, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Оценка модели\n",
    "def predict_and_evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score (weighted): {f1_weighted}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5298bf82-054b-4cc1-8f81-64360bfcfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_title'] = train_df['title'].apply(clean_title)\n",
    "test_df['cleaned_title'] = test_df['title'].apply(clean_title)\n",
    "\n",
    "# Кодирование пола\n",
    "le_sex = LabelEncoder()\n",
    "train_df['sex'] = le_sex.fit_transform(train_df['sex'])\n",
    "test_df['sex'] = le_sex.transform(test_df['sex'])  # Применение обученного на train LabelEncoder\n",
    "\n",
    "# Преобразование возраста\n",
    "train_df['age_class'] = train_df['age_class'].astype(int)\n",
    "test_df['age_class'] = test_df['age_class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a88607-f7d3-41ec-947f-6d030f07638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jet\\anaconda3\\envs\\cud1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|██████████████████████████████████████████████████████████| 5511/5511 [13:21<00:00,  6.88it/s]\n",
      "C:\\Users\\Jet\\anaconda3\\envs\\cud1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|██████████████████████████████████████████████████████████| 1364/1364 [03:23<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_df = generate_embeddings(train_df, batch_size=256)\n",
    "test_df = generate_embeddings(test_df, batch_size=256)\n",
    "\n",
    "\n",
    "clean_train_df = aggregate_user_data(clean_df)\n",
    "clean_test_df = aggregate_user_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87e87659-fb5c-4f90-a16d-c2a8341f848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3526715\ttotal: 232ms\tremaining: 3m 52s\n",
      "100:\tlearn: 1.1106214\ttotal: 21.1s\tremaining: 3m 7s\n",
      "200:\tlearn: 1.0883944\ttotal: 41.8s\tremaining: 2m 46s\n",
      "300:\tlearn: 1.0737246\ttotal: 1m 1s\tremaining: 2m 23s\n",
      "400:\tlearn: 1.0618193\ttotal: 1m 22s\tremaining: 2m 2s\n",
      "500:\tlearn: 1.0518750\ttotal: 1m 41s\tremaining: 1m 41s\n",
      "600:\tlearn: 1.0424975\ttotal: 2m 1s\tremaining: 1m 20s\n",
      "700:\tlearn: 1.0332533\ttotal: 2m 22s\tremaining: 1m\n",
      "800:\tlearn: 1.0245570\ttotal: 2m 43s\tremaining: 40.6s\n",
      "900:\tlearn: 1.0164232\ttotal: 3m 3s\tremaining: 20.2s\n",
      "999:\tlearn: 1.0085103\ttotal: 3m 22s\tremaining: 0us\n",
      "Accuracy: 0.46579451712357306\n",
      "F1 Score (weighted): 0.4541013123560947\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.01      0.01      1578\n",
      "           1       0.49      0.58      0.53     12552\n",
      "           2       0.42      0.43      0.43     13070\n",
      "           3       0.49      0.44      0.46      8803\n",
      "\n",
      "    accuracy                           0.47     36003\n",
      "   macro avg       0.42      0.36      0.36     36003\n",
      "weighted avg       0.46      0.47      0.45     36003\n",
      "\n",
      "0:\tlearn: 0.6694691\ttotal: 137ms\tremaining: 2m 16s\n",
      "100:\tlearn: 0.5108396\ttotal: 7.05s\tremaining: 1m 2s\n",
      "200:\tlearn: 0.4958296\ttotal: 13.9s\tremaining: 55.2s\n",
      "300:\tlearn: 0.4848656\ttotal: 20.5s\tremaining: 47.7s\n",
      "400:\tlearn: 0.4759501\ttotal: 27.1s\tremaining: 40.4s\n",
      "500:\tlearn: 0.4683277\ttotal: 34s\tremaining: 33.9s\n",
      "600:\tlearn: 0.4612769\ttotal: 40.3s\tremaining: 26.8s\n",
      "700:\tlearn: 0.4545842\ttotal: 46.8s\tremaining: 19.9s\n",
      "800:\tlearn: 0.4484647\ttotal: 53.1s\tremaining: 13.2s\n",
      "900:\tlearn: 0.4425956\ttotal: 59.3s\tremaining: 6.52s\n",
      "999:\tlearn: 0.4370325\ttotal: 1m 5s\tremaining: 0us\n",
      "Accuracy: 0.7480765491764575\n",
      "F1 Score (weighted): 0.7479847004799662\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74     18056\n",
      "           1       0.74      0.77      0.75     17947\n",
      "\n",
      "    accuracy                           0.75     36003\n",
      "   macro avg       0.75      0.75      0.75     36003\n",
      "weighted avg       0.75      0.75      0.75     36003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Подготовка данных\n",
    "def prepare_data(df, target_column):\n",
    "    X = df.drop(columns=['age_class', 'sex', 'age', 'viewer_uid', 'mean_title_embedding'])\n",
    "    embeddings = np.vstack(df['mean_title_embedding'].values)\n",
    "    X = pd.concat([X, pd.DataFrame(embeddings)], axis=1)\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Определение категориальных признаков (если они есть)\n",
    "def get_categorical_features_indices(X):\n",
    "    return np.where(X.dtypes == 'object')[0]\n",
    "\n",
    "# Обучение модели с использованием CatBoost\n",
    "def train_model_catboost(X_train, y_train, cat_features):\n",
    "    \n",
    "    model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, \n",
    "                               cat_features=cat_features, verbose=100, random_seed=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Оценка модели\n",
    "def predict_and_evaluate_catboost(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score (weighted): {f1_weighted}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Универсальная функция для обучения и тестирования\n",
    "def train_and_evaluate(df_train, df_test, target_column):\n",
    "    # Подготовка данных\n",
    "    X_train, y_train = prepare_data(df_train, target_column)\n",
    "    X_test, y_test = prepare_data(df_test, target_column)\n",
    "    \n",
    "    # Определение категориальных признаков\n",
    "    categorical_features_indices = get_categorical_features_indices(X_train)\n",
    "    \n",
    "    # Обучение модели\n",
    "    model = train_model_catboost(X_train, y_train, categorical_features_indices)\n",
    "    \n",
    "    # Оценка модели\n",
    "    predict_and_evaluate_catboost(model, X_test, y_test)\n",
    "\n",
    "# Пример использования для предсказания возраста\n",
    "model_age = train_and_evaluate(clean_train_df, clean_test_df, 'age_class')\n",
    "\n",
    "# Пример использования для предсказания пола\n",
    "model_sex = train_and_evaluate(clean_train_df, clean_test_df, 'sex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "781e863f-1588-4d7e-9e3e-9a6999630f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_user_data(clean_df):\n",
    "    user_embeddings = clean_df.groupby('viewer_uid')['title_embedding1'].apply(lambda x: np.mean(x.tolist(), axis=0))\n",
    "    user_info = clean_df.groupby('viewer_uid').agg({\n",
    "\n",
    "        'region': lambda x: x.mode()[0],\n",
    "        'ua_device_type': lambda x: x.mode()[0],\n",
    "        'ua_client_type': lambda x: x.mode()[0],\n",
    "        'ua_os': lambda x: x.mode()[0],\n",
    "        'ua_client_name': lambda x: x.mode()[0],\n",
    "        'total_watchtime': 'sum',\n",
    "        'category': lambda x: x.mode()[0],\n",
    "        'duration': 'sum',\n",
    "\n",
    "    }).reset_index()\n",
    "    user_info['mean_title_embedding'] = user_embeddings.values\n",
    "    return user_info\n",
    "\n",
    "def pred(train_data,model):\n",
    "    \n",
    "    categorical_features = [\n",
    "        'region', 'ua_device_type', 'ua_client_type', 'ua_os',\n",
    "        'ua_client_name', 'rutube_video_id', 'author_id', 'category'\n",
    "    ]\n",
    "    categorical_mapping = {}\n",
    "    num_unique = {}\n",
    "    for col in categorical_features:\n",
    "        unique_values = train_data[col].astype(str).unique().tolist()\n",
    "        mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "        categorical_mapping[col] = mapping\n",
    "        num_unique[col] = len(mapping) + 1  \n",
    "        train_data[col] = train_data[col].astype(str).map(mapping)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_data['cleaned_title'] = train_data['title'].apply(clean_title)\n",
    "    le_sex = LabelEncoder()\n",
    "    clean_df = generate_embeddings(train_data, batch_size=256)\n",
    "    clean_train_df = aggregate_user_data(clean_df)\n",
    "    X_train_embeddings = np.vstack(clean_train_df['mean_title_embedding'].values)\n",
    "    X_train = pd.concat([clean_train_df.drop(columns=['mean_title_embedding']), pd.DataFrame(X_train_embeddings)], axis=1)\n",
    "    y_pred = model.predict(X_train)\n",
    "\n",
    "    return   y_pred,clean_train_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65af6d85-9240-4786-bf2a-12ccb23e9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = pd.read_csv('all_events.csv')\n",
    "train_events = pd.read_csv('train_events.csv')\n",
    "video_info = pd.read_csv('video_info_v2.csv')\n",
    "train_targets = pd.read_csv('train_targets.csv')\n",
    "\n",
    "# Объединение данных\n",
    "train_data = pd.merge(train_events, train_targets, on='viewer_uid', how='left')\n",
    "train_data = pd.merge(train_data, video_info, on='rutube_video_id', how='left')\n",
    "\n",
    "train_data =train_data.head(1000)\n",
    "\n",
    "train_data= train_data.drop(columns=['age_class', 'sex', 'age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4f68e96-0da9-4e37-bbe0-2bf635ba345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jet\\anaconda3\\envs\\cud1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.36it/s]\n",
      "C:\\Users\\Jet\\anaconda3\\envs\\cud1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Processing batches: 100%|████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.68it/s]\n"
     ]
    }
   ],
   "source": [
    "data_sex,client_df= pred(train_data,model_sex)\n",
    "data_age,client_df= pred(train_data,model_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cd4942c0-a2cb-4d9c-bdae-2ce87effb26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность y_pred_sex: (738,)\n",
      "Размерность y_pred_age_class: (738, 1)\n",
      "Размерность viewer_uid: (738,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размерность y_pred_sex:\", data_sex.shape)\n",
    "print(\"Размерность y_pred_age_class:\", data_age.shape)\n",
    "print(\"Размерность viewer_uid:\", client_df['viewer_uid'].shape)\n",
    "\n",
    "# Преобразование предсказаний в одномерные массивы (если они многомерные)\n",
    "y_pred_sex = data_sex.flatten() if len(data_sex.shape) > 1 else data_sex\n",
    "y_pred_age_class = data_age.flatten() if len(data_age.shape) > 1 else data_age\n",
    "viewer_uid = client_df['viewer_uid'].values.flatten() if len(client_df['viewer_uid'].shape) > 1 else client_df['viewer_uid'].values\n",
    "\n",
    "# Убедимся, что все массивы имеют одинаковую длину\n",
    "assert len(viewer_uid) == len(y_pred_sex) == len(y_pred_age_class), \"Размерности данных не совпадают!\"\n",
    "\n",
    "# Формирование датафрейма с результатами\n",
    "result_df = pd.DataFrame({\n",
    "    'viewer_uid': viewer_uid,  # Убедитесь, что это одномерный массив\n",
    "    'sex': y_pred_sex,  # Предсказанные значения пола\n",
    "    'age_class': y_pred_age_class  # Предсказанные значения возрастной категории\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
